# Required
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_KEY=your_service_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Batch API Configuration (New!)
USE_BATCH_API=true              # Enable batch API for cost savings
BATCH_API_THRESHOLD=100         # Use batch API when chunks >= 100
BATCH_API_WAIT_TIMEOUT=300      # Max seconds to wait for small batches
BATCH_CHECK_INTERVAL=300        # Check pending batches every 5 minutes
AUTO_PROCESS_BATCHES=true       # Automatically process batch jobs
PREFER_COST_SAVINGS=true        # Prefer batch API when possible
MAX_REGULAR_API_BATCH=20        # Max embeddings per regular API call

# Processing Configuration
CHUNK_SIZE=1024
CHUNK_OVERLAP=200
MAX_FILE_SIZE_MB=100
BATCH_SIZE=100
MAX_CONCURRENT_FILES=5

# Feature Toggles
ENABLE_SEMANTIC_CHUNKING=true
ENABLE_HIERARCHICAL_CHUNKING=true
EXTRACT_METADATA=true
ENABLE_OCR=true
ENABLE_SPEECH_TO_TEXT=true

# Model Configuration
EMBEDDING_MODEL=text-embedding-3-large
LLM_MODEL=gpt-4-turbo

# Service Configuration
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO