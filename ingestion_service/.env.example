# LlamaIndex Ingestion Service Configuration

# Required Configuration
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_KEY=your_service_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Chunking Configuration
CHUNK_SIZE=1024
CHUNK_OVERLAP=200
ENABLE_SEMANTIC_CHUNKING=true
ENABLE_HIERARCHICAL_CHUNKING=true

# Processing Configuration
EXTRACT_METADATA=true
ENABLE_OCR=true
ENABLE_SPEECH_TO_TEXT=true
MAX_FILE_SIZE_MB=100

# Database Configuration
TABLE_NAME=rag_documents

# Model Configuration
EMBEDDING_MODEL=text-embedding-3-large
LLM_MODEL=gpt-4-turbo

# Performance Configuration
MAX_CONCURRENT_FILES=5
BATCH_SIZE=100
MEMORY_LIMIT_GB=8.0
CPU_LIMIT=4

# Cache Configuration
CACHE_DIR=./ingestion_cache
ENABLE_CACHE=true

# Logging Configuration
LOG_LEVEL=INFO
# LOG_FILE=./logs/ingestion.log

# File Type Specific Settings
OCR_CONFIDENCE_THRESHOLD=0.5
AUDIO_CHUNK_DURATION=30
CODE_CHUNK_LINES=40

# Supported Extensions (comma-separated)
# SUPPORTED_EXTENSIONS=pdf,docx,txt,md,csv,xlsx,jpg,png,mp3,wav,py,js,json,html

# Service Configuration
HOST=0.0.0.0
PORT=8000
RELOAD=false